{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.820444 -> [ 0.7785638   0.17644775] [1 0]\n",
      "[[ 0.42745098  0.4         0.36862745 ...,  0.18039216  0.08235294\n",
      "   0.06666667]\n",
      " [ 0.40392157  0.35686275  0.2627451  ...,  0.16078431  0.11764706\n",
      "   0.14117647]\n",
      " [ 0.23529412  0.1372549   0.12156863 ...,  0.36078431  0.11764706\n",
      "   0.21568627]\n",
      " ..., \n",
      " [ 0.60784314  0.43137255  0.34901961 ...,  0.19215686  0.10588235\n",
      "   0.11764706]\n",
      " [ 0.41176471  0.28235294  0.24705882 ...,  0.38823529  0.27843137\n",
      "   0.19215686]\n",
      " [ 0.          0.00392157  0.         ...,  0.          0.00392157\n",
      "   0.01960784]]\n",
      "1: 13963.5 -> [-179.78222656  171.47874451] [1 0]\n",
      "2: 6.65374e+08 -> [ 14878.20507812 -14850.13378906] [1 0]\n",
      "3: 3.57617e+07 -> [-3879.42919922  6603.88378906] [0 1]\n",
      "4: 299687.0 -> [-575.04150391  518.39080811] [1 0]\n",
      "5: 446401.0 -> [-706.7364502  627.1751709] [1 0]\n",
      "6: 591358.0 -> [-817.00469971  717.83569336] [1 0]\n",
      "7: 724631.0 -> [-907.0793457   791.44152832] [1 0]\n",
      "8: 828642.0 -> [-954.19421387  866.4239502 ] [1 0]\n",
      "9: 6.57381e+15 -> [ 66663184. -61471804.] [1 0]\n",
      "10: 2.14096e+12 -> [-1521267.5    1402731.625] [1 0]\n",
      "11: 4.23865e+12 -> [-2140490.75  1973728.  ] [1 0]\n",
      "12: 6.59919e+12 -> [-2670813.75  2462748.5 ] [1 0]\n",
      "13: 8.98615e+12 -> [-3116623.25  2873838.25] [0 1]\n",
      "14: 1.1221e+13 -> [-3482673.25  3211381.  ] [1 0]\n",
      "15: 1.31768e+13 -> [-3773997.   3480017.5] [0 1]\n",
      "16: 1.47713e+13 -> [-3995826.75  3684572.5 ] [0 1]\n",
      "17: 1.59603e+13 -> [-4153518.5   3829985.25] [1 0]\n",
      "18: 1.67299e+13 -> [-4252487.    3921248.25] [0 1]\n",
      "19: 1.70911e+13 -> [-4298143.  3963351.] [0 1]\n",
      "20: 1.70728e+13 -> [-4295841.  3961231.] [1 0]\n",
      "21: 1.67169e+13 -> [-4250831.5  3919730. ] [1 0]\n",
      "22: 1.60735e+13 -> [-4168219.75  3843555.  ] [1 0]\n",
      "23: 1.51966e+13 -> [-4052930.5   3737247.75] [1 0]\n",
      "24: 1.41414e+13 -> [-3909678.5  3605155.5] [0 1]\n",
      "25: 1.29609e+13 -> [-3742944.25  3451409.75] [0 1]\n",
      "26: 1.17049e+13 -> [-3556954.5  3279908. ] [0 1]\n",
      "27: 1.04176e+13 -> [-3355668.  3094301.] [1 0]\n",
      "28: 9.13764e+12 -> [-3142765.    2897982.25] [0 1]\n",
      "29: 7.89703e+12 -> [-2921641.    2694082.25] [1 0]\n",
      "30: 6.72137e+12 -> [-2695403.    2485466.75] [1 0]\n",
      "31: 2.82536e+12 -> [-1743921.   1628012.5] [1 0]\n",
      "32: inf -> [  2.73581473e+19  -2.56039996e+19] [1 0]\n",
      "33: 4.09262e+35 -> [ -6.60562259e+17   6.18208659e+17] [1 0]\n",
      "34: nan -> [ nan  nan] [1 0]\n",
      "35: nan -> [ nan  nan] [1 0]\n",
      "36: nan -> [ nan  nan] [0 1]\n",
      "37: nan -> [ nan  nan] [0 1]\n",
      "38: nan -> [ nan  nan] [1 0]\n",
      "39: nan -> [ nan  nan] [1 0]\n",
      "40: nan -> [ nan  nan] [0 1]\n",
      "41: nan -> [ nan  nan] [0 1]\n",
      "42: nan -> [ nan  nan] [1 0]\n",
      "43: nan -> [ nan  nan] [1 0]\n",
      "44: nan -> [ nan  nan] [0 1]\n",
      "45: nan -> [ nan  nan] [1 0]\n",
      "46: nan -> [ nan  nan] [1 0]\n",
      "47: nan -> [ nan  nan] [1 0]\n",
      "48: nan -> [ nan  nan] [0 1]\n",
      "49: nan -> [ nan  nan] [1 0]\n",
      "50: nan -> [ nan  nan] [0 1]\n",
      "51: nan -> [ nan  nan] [1 0]\n",
      "52: nan -> [ nan  nan] [1 0]\n",
      "53: nan -> [ nan  nan] [1 0]\n",
      "54: nan -> [ nan  nan] [0 1]\n",
      "55: nan -> [ nan  nan] [0 1]\n",
      "56: nan -> [ nan  nan] [0 1]\n",
      "57: nan -> [ nan  nan] [1 0]\n",
      "58: nan -> [ nan  nan] [0 1]\n",
      "59: nan -> [ nan  nan] [0 1]\n",
      "60: nan -> [ nan  nan] [0 1]\n",
      "61: nan -> [ nan  nan] [1 0]\n",
      "62: nan -> [ nan  nan] [0 1]\n",
      "63: nan -> [ nan  nan] [0 1]\n",
      "64: nan -> [ nan  nan] [1 0]\n",
      "65: nan -> [ nan  nan] [1 0]\n",
      "66: nan -> [ nan  nan] [1 0]\n",
      "67: nan -> [ nan  nan] [1 0]\n",
      "68: nan -> [ nan  nan] [0 1]\n",
      "69: nan -> [ nan  nan] [0 1]\n",
      "70: nan -> [ nan  nan] [1 0]\n",
      "71: nan -> [ nan  nan] [1 0]\n",
      "72: nan -> [ nan  nan] [0 1]\n",
      "73: nan -> [ nan  nan] [1 0]\n",
      "74: nan -> [ nan  nan] [0 1]\n",
      "75: nan -> [ nan  nan] [1 0]\n",
      "76: nan -> [ nan  nan] [1 0]\n",
      "77: nan -> [ nan  nan] [0 1]\n",
      "78: nan -> [ nan  nan] [1 0]\n",
      "79: nan -> [ nan  nan] [0 1]\n",
      "80: nan -> [ nan  nan] [1 0]\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n",
      "\n",
      "Caused by op u'input_producer/input_producer_EnqueueMany', defined at:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-482b7e3cf4e4>\", line 69, in <module>\n",
      "    path_batch, label_batch = input_pipeline(people_path, batch_size, None, True)\n",
      "  File \"dataset.py\", line 107, in input_pipeline\n",
      "    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 232, in string_input_producer\n",
      "    cancel_op=cancel_op)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 164, in input_producer\n",
      "    enq = q.enqueue_many([input_tensor])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1556, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-482b7e3cf4e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d: %s -> %s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1 -> male, 2 -> female\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/book/people_classification/dataset.pyc\u001b[0m in \u001b[0;36mimages_as_float\u001b[0;34m(img, batch_size, data_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimages_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2574\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2650\u001b[0m                       for a in args]\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2652\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/book/people_classification/dataset.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mvfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimages_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from dataset import path_to_image_crop, input_pipeline, images_as_float\n",
    "\n",
    "def model1(x, y_, data_size):\n",
    "    W = tf.Variable(tf.zeros([data_size, 1]))\n",
    "    b = tf.Variable(tf.zeros([2]))\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    return tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy), y, cross_entropy\n",
    "\n",
    "def model2(x, y_):\n",
    "    def fully_connected(input, size):\n",
    "        weights = tf.get_variable( 'weights', \n",
    "            shape = [input.get_shape()[1], size],\n",
    "            initializer = tf.contrib.layers.xavier_initializer()\n",
    "          )\n",
    "        biases = tf.get_variable( 'biases',\n",
    "            shape = [size],\n",
    "            initializer=tf.constant_initializer(0.0)\n",
    "          )\n",
    "        return tf.matmul(input, weights) + biases\n",
    "    def model_pass(input):\n",
    "        with tf.variable_scope('hidden'):\n",
    "            hidden = fully_connected(input, size = 100)\n",
    "        relu_hidden = tf.nn.relu(hidden)\n",
    "        with tf.variable_scope('out'):\n",
    "            prediction = fully_connected(relu_hidden, size = 2)\n",
    "        return prediction   \n",
    "    \n",
    "    predictions = model_pass(x)  \n",
    "    loss = tf.reduce_mean(tf.square(predictions - y_))\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "        learning_rate = 0.01, \n",
    "        momentum = 0.9, \n",
    "        use_nesterov = True\n",
    "    ).minimize(loss)\n",
    "    \n",
    "    return optimizer, predictions, loss\n",
    "\n",
    "people_path = '/data/people_classification_all/fold_*_data.txt'\n",
    "image_prefix = 'coarse_tilt_aligned_face'\n",
    "batch_size = 128\n",
    "image_size = 227\n",
    "image_dimension = [image_size,image_size]\n",
    "num_epochs = 1000\n",
    "\n",
    "model_name = \"1fc_b\" + str(batch_size) + \"_e\" + str(num_epochs - 1)\n",
    "model_variable_scope = model_name\n",
    "\n",
    "def extract_gender(features):\n",
    "    def extract(v):\n",
    "        def f1(): return tf.constant([1,0])\n",
    "        def f2(): return tf.constant([0,1])\n",
    "        def f_(): return tf.constant([0,0])\n",
    "        return tf.case({\n",
    "            tf.equal(v[1], tf.constant(1)): f1,\n",
    "            tf.equal(v[1], tf.constant(2)): f2,\n",
    "            }, default=f_, exclusive=True)\n",
    "    return tf.map_fn(extract, features, dtype=tf.int32)\n",
    "\n",
    "\n",
    "data_size = image_dimension[0] * image_dimension[1] * 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    path_batch, label_batch = input_pipeline(people_path, batch_size, None, True)\n",
    "    label_batch = extract_gender(label_batch)\n",
    "    label_batch = tf.reshape(label_batch,[batch_size,2])\n",
    "\n",
    "    data_batch = path_to_image_crop(path_batch, os.path.dirname(people_path), image_prefix, image_dimension)\n",
    "    data_batch = tf.reshape(data_batch,[batch_size, data_size])\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, data_size])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "    \n",
    "    #train_step, y, loss = model1(x, y_, data_size)\n",
    "    train_step, y, loss = model2(x, y_)\n",
    "\n",
    "with tf.Session(graph = graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator ()\n",
    "    threads = tf.train.start_queue_runners (coord = coord)\n",
    "    for i in range(num_epochs):\n",
    "        batch_xs, batch_ys = session.run([data_batch, label_batch])\n",
    "        batch_xs = images_as_float(batch_xs, batch_size, data_size)\n",
    "        p,l,_ = session.run([y, loss, train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        print('%d: %s -> %s %s' % (i, l, p[i % batch_size], batch_ys[i % batch_size])) # 1 -> male, 2 -> female\n",
    "        if (i == 0): print(batch_xs)\n",
    "    coord.request_stop ()\n",
    "    coord.join (threads)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
